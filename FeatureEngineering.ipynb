{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date column sample:\n",
      "0   2013-08-09\n",
      "1   2013-08-10\n",
      "2   2013-08-10\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "Date range: 2013-08-09 00:00:00 to 2017-05-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "    'Datasets/Processed/season-1314_with_weather.csv',\n",
    "    'Datasets/Processed/season-1415_with_weather.csv',\n",
    "    'Datasets/Processed/season-1516_with_weather.csv',\n",
    "    'Datasets/Processed/season-1617_with_weather.csv'\n",
    "]\n",
    "\n",
    "train_dfs = []\n",
    "for i, file in enumerate(train_files):\n",
    "    df = pd.read_csv(file, parse_dates=['Date'], date_format='%d/%m/%y')\n",
    "    df['season'] = 2013 + i\n",
    "    train_dfs.append(df)\n",
    "\n",
    "train_raw = pd.concat(train_dfs).sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Verification\n",
    "print(\"Date column sample:\")\n",
    "print(train_raw['Date'].head(3))\n",
    "print(\"\\nDate range:\", train_raw['Date'].min(), \"to\", train_raw['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Comprehensive feature engineering with all pre-match features\"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. League averages for fallback\n",
    "    # -------------------------------------------------------------------------\n",
    "    df['league_home_avg'] = df.groupby('season')['FTHG'].transform('mean')\n",
    "    df['league_away_avg'] = df.groupby('season')['FTAG'].transform('mean')\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. Team Form Features (Basic)\n",
    "    # -------------------------------------------------------------------------\n",
    "    for team_type in ['HomeTeam', 'AwayTeam']:\n",
    "        # Goals scored/conceded\n",
    "        df[f'{team_type}_goals_5avg'] = df.groupby(team_type)['FTHG' if team_type=='HomeTeam' else 'FTAG']\\\n",
    "                                        .transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())\n",
    "        \n",
    "        # Win percentage\n",
    "        df[f'{team_type}_win_pct'] = df.groupby(team_type)['FTR']\\\n",
    "                                    .transform(lambda x: (x.shift(1) == ('H' if team_type=='HomeTeam' else 'A')))\\\n",
    "                                    .rolling(10, min_periods=3).mean()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3. Defensive Stability Features\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Home Team\n",
    "    df['Home_clean_sheets_5'] = df.groupby('HomeTeam')['FTAG']\\\n",
    "                                .transform(lambda x: (x.shift(1) == 0).rolling(5, min_periods=3).sum())\n",
    "    df['Home_goals_conceded_5avg'] = df.groupby('HomeTeam')['FTAG']\\\n",
    "                                     .transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean())\n",
    "    \n",
    "    # Away Team\n",
    "    df['Away_clean_sheets_5'] = df.groupby('AwayTeam')['FTHG']\\\n",
    "                                .transform(lambda x: (x.shift(1) == 0).rolling(5, min_periods=3).sum())\n",
    "    df['Away_goals_conceded_5avg'] = df.groupby('AwayTeam')['FTHG']\\\n",
    "                                     .transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean())\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4. Attack Efficiency Features\n",
    "    # -------------------------------------------------------------------------\n",
    "    df['Home_shot_conv_3'] = (df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean())) / \\\n",
    "                            (df.groupby('HomeTeam')['HS'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean() + 0.001))\n",
    "    \n",
    "    df['Away_shot_conv_3'] = (df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean())) / \\\n",
    "                            (df.groupby('AwayTeam')['AS'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean() + 0.001))\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5. Discipline Features\n",
    "    # -------------------------------------------------------------------------\n",
    "    df['Home_avg_cards_5'] = df.groupby('HomeTeam')['HY']\\\n",
    "                             .transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean())\n",
    "    df['Away_avg_cards_5'] = df.groupby('AwayTeam')['AY']\\\n",
    "                             .transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean())\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6. Comeback Ability Features\n",
    "    # -------------------------------------------------------------------------\n",
    "    def calculate_comeback(group):\n",
    "        return ((group['FTR'].shift(1) == 'H') & (group['HTR'].shift(1) == 'A')).astype(int)\n",
    "    \n",
    "    df['Home_comeback_pts_10'] = df.groupby('HomeTeam').apply(calculate_comeback)\\\n",
    "                                  .reset_index(level=0, drop=True)\\\n",
    "                                  .rolling(10, min_periods=5).sum()\n",
    "    \n",
    "    df['Away_comeback_pts_10'] = df.groupby('AwayTeam').apply(\n",
    "        lambda x: ((x['FTR'].shift(1) == 'A') & (x['HTR'].shift(1) == 'H')).astype(int))\\\n",
    "                                  .reset_index(level=0, drop=True)\\\n",
    "                                  .rolling(10, min_periods=5).sum()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 7. Head-to-Head Features\n",
    "    # -------------------------------------------------------------------------\n",
    "    df['h2h_goal_diff'] = df.apply(lambda row: get_h2h_diff(row['HomeTeam'], row['AwayTeam'], row['Date'], df), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_h2h_diff(home, away, date, full_df):\n",
    "    \"\"\"Calculate historical goal difference between teams\"\"\"\n",
    "    past_matches = full_df[\n",
    "        (full_df['Date'] < date) & \n",
    "        (full_df['HomeTeam'] == home) & \n",
    "        (full_df['AwayTeam'] == away)\n",
    "    ]\n",
    "    return (past_matches['FTHG'].mean() - past_matches['FTAG'].mean()) if len(past_matches) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total engineered features: 26\n",
      "['HomeTeam', 'AwayTeam', 'HTHG', 'HTAG', 'HTR', 'Referee', 'temperature', 'wind_speed', 'precipitation', 'league_home_avg', 'league_away_avg', 'HomeTeam_goals_5avg', 'HomeTeam_win_pct', 'AwayTeam_goals_5avg', 'AwayTeam_win_pct', 'Home_clean_sheets_5', 'Home_goals_conceded_5avg', 'Away_clean_sheets_5', 'Away_goals_conceded_5avg', 'Home_shot_conv_3', 'Away_shot_conv_3', 'Home_avg_cards_5', 'Away_avg_cards_5', 'Home_comeback_pts_10', 'Away_comeback_pts_10', 'h2h_goal_diff']\n",
      "\n",
      "Feature example for Toulouse vs Nantes:\n",
      "Home 5-game goal avg: 1.20\n",
      "Home shot conversion: 6.67%\n",
      "Home comeback pts: 0.0\n"
     ]
    }
   ],
   "source": [
    "train_engineered = create_features(train_raw)\n",
    "all_features = [col for col in train_engineered.columns \n",
    "                if col not in ['Date', 'FTR', 'FTHG', 'FTAG', 'season', \n",
    "                              'HS', 'AS', 'HST', 'AST', 'HC', 'AC', \n",
    "                              'HF', 'AF', 'HY', 'AY', 'HR', 'AR',]] # 'temperature', 'wind_speed', 'precipitation'\n",
    "\n",
    "print(f\"Total engineered features: {len(all_features)}\")\n",
    "print(all_features)\n",
    "# Check temporal integrity\n",
    "sample = train_engineered.iloc[1000]\n",
    "print(f\"\\nFeature example for {sample['HomeTeam']} vs {sample['AwayTeam']}:\")\n",
    "print(f\"Home 5-game goal avg: {sample['HomeTeam_goals_5avg']:.2f}\")\n",
    "print(f\"Home shot conversion: {sample['Home_shot_conv_3']:.2%}\")\n",
    "print(f\"Home comeback pts: {sample['Home_comeback_pts_10']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset: 1520 matches\n",
      "First match: 2013-08-09\n",
      "Last match: 2017-05-20\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Feature NA Handling\n",
    "Filling missing values with appropriate defaults\n",
    "\"\"\"\n",
    "features = [\n",
    "    # Basic form\n",
    "    'HomeTeam_goals_5avg', 'AwayTeam_goals_5avg',\n",
    "    'HomeTeam_win_pct', 'AwayTeam_win_pct',\n",
    "    'h2h_goal_diff',\n",
    "    \n",
    "    # Defensive stability\n",
    "    'Home_goals_conceded_5avg', 'Away_goals_conceded_5avg',\n",
    "    'Home_clean_sheets_5', 'Away_clean_sheets_5',\n",
    "    \n",
    "    # Attack efficiency\n",
    "    'Home_shot_conv_3', 'Away_shot_conv_3',\n",
    "    \n",
    "    # Discipline\n",
    "    'Home_avg_cards_5', 'Away_avg_cards_5',\n",
    "    \n",
    "    # Comeback ability\n",
    "    'Home_comeback_pts_10', 'Away_comeback_pts_10',\n",
    "\n",
    "    # Weather\n",
    "    'temperature', 'wind_speed', 'precipitation'\n",
    "]# Corrected fill values dictionary\n",
    "\n",
    "fill_values = {\n",
    "    # Goals and defense - use league averages\n",
    "    **{f'{team}Team_goals_5avg': train_engineered[f'league_{team.lower()}_avg'] \n",
    "       for team in ['Home', 'Away']},\n",
    "    **{f'{team}_goals_conceded_5avg': train_engineered[f'league_{team.lower()}_avg'] \n",
    "       for team in ['Home', 'Away']},  # Removed \"Team\" from column name\n",
    "    **{f'{team}_clean_sheets_5': 0 for team in ['Home', 'Away']},\n",
    "    \n",
    "    # Attack efficiency\n",
    "    'Home_shot_conv_3': train_engineered['FTHG'].mean() / (train_engineered['HS'].mean() + 0.001),\n",
    "    'Away_shot_conv_3': train_engineered['FTAG'].mean() / (train_engineered['AS'].mean() + 0.001),\n",
    "    \n",
    "    # Win percentages\n",
    "    'HomeTeam_win_pct': 0.5,\n",
    "    'AwayTeam_win_pct': 0.5,\n",
    "    \n",
    "    # Discipline\n",
    "    'Home_avg_cards_5': train_engineered['HY'].mean(),\n",
    "    'Away_avg_cards_5': train_engineered['AY'].mean(),\n",
    "    \n",
    "    # Comeback ability\n",
    "    'Home_comeback_pts_10': 0,\n",
    "    'Away_comeback_pts_10': 0,\n",
    "    \n",
    "    # Head-to-head\n",
    "    'h2h_goal_diff': 0\n",
    "}\n",
    "\n",
    "# Apply filling\n",
    "for feature, fill_value in fill_values.items():\n",
    "    if feature in train_engineered.columns:  # Safe check\n",
    "        train_engineered[feature] = train_engineered[feature].fillna(fill_value)\n",
    "    else:\n",
    "        print(f\"Warning: {feature} not found in dataframe\")\n",
    "\n",
    "# Final cleanup\n",
    "train_final = train_engineered.dropna(subset=features)\n",
    "print(f\"\\nFinal dataset: {len(train_final)} matches\")\n",
    "print(f\"First match: {train_final['Date'].min().date()}\")\n",
    "print(f\"Last match: {train_final['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files with 1520 matches\n",
      "Columns in final CSV:\n",
      "['Date', 'HomeTeam', 'AwayTeam', 'season', 'HomeTeam_goals_5avg', 'AwayTeam_goals_5avg', 'HomeTeam_win_pct', 'AwayTeam_win_pct', 'h2h_goal_diff', 'Home_goals_conceded_5avg', 'Away_goals_conceded_5avg', 'Home_clean_sheets_5', 'Away_clean_sheets_5', 'Home_shot_conv_3', 'Away_shot_conv_3', 'Home_avg_cards_5', 'Away_avg_cards_5', 'Home_comeback_pts_10', 'Away_comeback_pts_10', 'temperature', 'wind_speed', 'precipitation', 'FTR']\n",
      "\n",
      "Sample row:\n",
      "{'Date': Timestamp('2013-08-09 00:00:00'), 'HomeTeam': 'Montpellier', 'AwayTeam': 'Paris SG', 'FTR': 'D', 'HomeTeam_goals_5avg': 1.4157894736842105, 'AwayTeam_goals_5avg': 1.0394736842105263, 'HomeTeam_win_pct': 0.5}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Select only safe columns to keep\n",
    "safe_columns = [\n",
    "    # Match identifiers\n",
    "    'Date', 'HomeTeam', 'AwayTeam', 'season',\n",
    "    \n",
    "    # Engineered features\n",
    "    *features,  # All our engineered features\n",
    "    \n",
    "    # Target variable\n",
    "    'FTR'\n",
    "]\n",
    "\n",
    "# 2. Create cleaned dataset\n",
    "clean_data = train_final[safe_columns].copy()\n",
    "\n",
    "# 3. Scale features (only the engineered ones)\n",
    "# scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform(clean_data[features])\n",
    "# clean_data[features] = scaled_features\n",
    "\n",
    "# 4. Save files\n",
    "clean_data.to_csv('Features/TrainingSet/matches_engineered_weather.csv', index=False)  # All safe data\n",
    "pd.DataFrame(clean_data[features], columns=features).to_csv('Features/TrainingSet/features_weather.csv', index=False)\n",
    "# joblib.dump(scaler, 'Features/TrainingSet/feature_scaler.pkl')\n",
    "\n",
    "# 5. Verification\n",
    "print(f\"\\nSaved files with {len(clean_data)} matches\")\n",
    "print(\"Columns in final CSV:\")\n",
    "print(clean_data.columns.tolist())\n",
    "print(\"\\nSample row:\")\n",
    "print(clean_data.iloc[0][['Date', 'HomeTeam', 'AwayTeam', 'FTR'] + features[:3]].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xn/ndw4xk5s48z5tr_mhb_d_6480000gn/T/ipykernel_38395/2653427866.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  val_raw = pd.read_csv('Datasets/Processed/season-1718_with_weather.csv', parse_dates=['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: 380 matches\n"
     ]
    }
   ],
   "source": [
    "# Load raw validation data\n",
    "val_raw = pd.read_csv('Datasets/Processed/season-1718_with_weather.csv', parse_dates=['Date'])\n",
    "\n",
    "# Add season marker\n",
    "val_raw['season'] = 2017\n",
    "\n",
    "# Apply the SAME feature engineering\n",
    "val_engineered = create_features(val_raw)  # Uses same function as training\n",
    "\n",
    "# Fill NAs using training league averages (not val averages!)\n",
    "for feature in features:\n",
    "    if feature in fill_values:  # Use the same fill values as training\n",
    "        val_engineered[feature] = val_engineered[feature].fillna(fill_values[feature])\n",
    "\n",
    "# Scale features (using TRAINING scaler)\n",
    "# X_val = scaler.transform(val_engineered[features])\n",
    "y_val = val_engineered['FTR']\n",
    "\n",
    "# Save validation files\n",
    "val_engineered.to_csv('Features/ValidationSet/matches_engineered_weather.csv', index=False)\n",
    "pd.DataFrame(val_engineered[features], columns=features).to_csv('Features/ValidationSet/features_weather.csv', index=False)\n",
    "\n",
    "print(f\"Validation set: {len(val_engineered)} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xn/ndw4xk5s48z5tr_mhb_d_6480000gn/T/ipykernel_38395/992204401.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_raw = pd.read_csv('Datasets/Processed/season-1819_with_weather.csv', parse_dates=['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 380 matches\n"
     ]
    }
   ],
   "source": [
    "# Load raw test data\n",
    "test_raw = pd.read_csv('Datasets/Processed/season-1819_with_weather.csv', parse_dates=['Date'])\n",
    "\n",
    "# Add season marker\n",
    "test_raw['season'] = 2018\n",
    "\n",
    "# Apply feature engineering\n",
    "test_engineered = create_features(test_raw)\n",
    "\n",
    "# Fill NAs (using training defaults)\n",
    "for feature in features:\n",
    "    if feature in fill_values:\n",
    "        test_engineered[feature] = test_engineered[feature].fillna(fill_values[feature])\n",
    "\n",
    "# Scale features\n",
    "# X_test = scaler.transform(test_engineered[features])\n",
    "y_test = test_engineered['FTR']\n",
    "\n",
    "# Save test files\n",
    "test_engineered.to_csv('Features/TestSet/matches_engineered_weather.csv', index=False)\n",
    "pd.DataFrame(test_engineered[features], columns=features).to_csv('Features/TestSet/features_weather.csv', index=False)\n",
    "\n",
    "print(f\"Test set: {len(test_engineered)} matches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
