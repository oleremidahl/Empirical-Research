{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1: Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOCK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Date               HomeTeam  AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       " 0  09/08/13            Montpellier  Paris SG     1     1   D   1.0   0.0   H   \n",
       " 1  10/08/13               Bordeaux    Monaco     0     2   A   0.0   0.0   D   \n",
       " 2  10/08/13  Evian Thonon Gaillard   Sochaux     1     1   D   1.0   0.0   H   \n",
       " 3  10/08/13                  Lille   Lorient     1     0   H   1.0   0.0   H   \n",
       " 4  10/08/13                   Lyon      Nice     4     0   H   1.0   0.0   H   \n",
       " \n",
       "    Referee  ...   AC   HY   AY   HR   AR  temperature  wind_speed  \\\n",
       " 0      NaN  ...  8.0  2.0  2.0  1.0  0.0    22.995833   28.020833   \n",
       " 1      NaN  ...  7.0  1.0  0.0  0.0  0.0    20.550000    6.437500   \n",
       " 2      NaN  ...  5.0  1.0  2.0  0.0  0.0    18.820833    8.229167   \n",
       " 3      NaN  ...  3.0  1.0  1.0  0.0  1.0    17.225000    9.391667   \n",
       " 4      NaN  ...  5.0  1.0  0.0  0.0  0.0    20.612500   13.066667   \n",
       " \n",
       "    precipitation  Season  Div  \n",
       " 0            0.0    1314  NaN  \n",
       " 1            0.0    1314  NaN  \n",
       " 2            0.0    1314  NaN  \n",
       " 3            0.0    1314  NaN  \n",
       " 4            0.0    1314  NaN  \n",
       " \n",
       " [5 rows x 27 columns],\n",
       "        Date     HomeTeam  AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  Referee  \\\n",
       " 0  10/08/18    Marseille  Toulouse     4     0   H     1     0   H      NaN   \n",
       " 1  11/08/18       Angers     Nimes     3     4   A     1     1   D      NaN   \n",
       " 2  11/08/18        Lille    Rennes     3     1   H     1     1   D      NaN   \n",
       " 3  11/08/18  Montpellier     Dijon     1     2   A     1     0   H      NaN   \n",
       " 4  11/08/18       Nantes    Monaco     1     3   A     0     0   D      NaN   \n",
       " \n",
       "    ...  HC  AC  HY  AY  HR  AR  temperature  wind_speed  precipitation  Season  \n",
       " 0  ...   5   1   1   3   0   0    24.787500   17.116667            0.0    1819  \n",
       " 1  ...   5   1   2   2   0   1    18.791667    5.920833            0.0    1819  \n",
       " 2  ...   2   6   1   0   0   0    16.908333    9.216667            1.2    1819  \n",
       " 3  ...   4   2   2   2   0   0    22.904167    8.229167            0.0    1819  \n",
       " 4  ...   7   2   1   0   0   0    19.058333    6.554167            0.0    1819  \n",
       " \n",
       " [5 rows x 26 columns])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List of seasons you want to load (excluding 2018-2019 for now)\n",
    "seasons_train = ['1314', '1415', '1516', '1617', '1718']\n",
    "\n",
    "# Initialize an empty list to store the training data\n",
    "train_data_list = []\n",
    "\n",
    "# Loop through each season and load the respective CSV file for training\n",
    "for season in seasons_train:\n",
    "    file_name = f'Datasets/Processed/season-{season}_with_weather.csv'  # Adjust the file path if necessary\n",
    "    season_data = pd.read_csv(file_name)\n",
    "    season_data['Season'] = season  # Add a column to keep track of the season\n",
    "    train_data_list.append(season_data)\n",
    "\n",
    "# Combine all the training data into a single DataFrame\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "\n",
    "# Load the 2018-2019 season separately for prediction and comparison\n",
    "test_season = '1819'\n",
    "test_data = pd.read_csv(f'Datasets/Processed/season-{test_season}_with_weather.csv')\n",
    "test_data['Season'] = test_season  # Add a column for season tracking\n",
    "\n",
    "# Preview the data\n",
    "train_data.head(), test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOCK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train after replace:\n",
      "0    0\n",
      "1    2\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: FTR, dtype: int64\n",
      "y_test after replace:\n",
      "0    1\n",
      "1    2\n",
      "2    1\n",
      "3    2\n",
      "4    2\n",
      "Name: FTR, dtype: int64\n",
      "X_train after team mapping:\n",
      "       Date HomeTeam AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  Referee  ...  \\\n",
      "0  09/08/13        0       19     1     1   D   1.0   0.0   H      NaN  ...   \n",
      "1  10/08/13        1       18     0     2   A   0.0   0.0   D      NaN  ...   \n",
      "2  10/08/13        2       10     1     1   D   1.0   0.0   H      NaN  ...   \n",
      "3  10/08/13        3       17     1     0   H   1.0   0.0   H      NaN  ...   \n",
      "4  10/08/13        4       13     4     0   H   1.0   0.0   H      NaN  ...   \n",
      "\n",
      "     AF   HC   AC   HY   AY   HR   AR  temperature  wind_speed  precipitation  \n",
      "0  18.0  1.0  8.0  2.0  2.0  1.0  0.0    22.995833   28.020833            0.0  \n",
      "1  11.0  3.0  7.0  1.0  0.0  0.0  0.0    20.550000    6.437500            0.0  \n",
      "2  18.0  5.0  5.0  1.0  2.0  0.0  0.0    18.820833    8.229167            0.0  \n",
      "3  18.0  4.0  3.0  1.0  1.0  0.0  1.0    17.225000    9.391667            0.0  \n",
      "4   9.0  2.0  5.0  1.0  0.0  0.0  0.0    20.612500   13.066667            0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "X_test after team mapping:\n",
      "       Date HomeTeam AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  Referee  ...  \\\n",
      "0  10/08/18       12       16     4     0   H     1     0   H      NaN  ...   \n",
      "1  11/08/18       24       30     3     4   A     1     1   D      NaN  ...   \n",
      "2  11/08/18        3        6     3     1   H     1     1   D      NaN  ...   \n",
      "3  11/08/18        0       26     1     2   A     1     0   H      NaN  ...   \n",
      "4  11/08/18        5       18     1     3   A     0     0   D      NaN  ...   \n",
      "\n",
      "   AF  HC  AC  HY  AY  HR  AR  temperature  wind_speed  precipitation  \n",
      "0  20   5   1   1   3   0   0    24.787500   17.116667            0.0  \n",
      "1  12   5   1   2   2   0   1    18.791667    5.920833            0.0  \n",
      "2  13   2   6   1   0   0   0    16.908333    9.216667            1.2  \n",
      "3  21   4   2   2   2   0   0    22.904167    8.229167            0.0  \n",
      "4  15   7   2   1   0   0   0    19.058333    6.554167            0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "X_train 'Referee' column after encoding:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: Referee, dtype: float64\n",
      "X_test 'Referee' column after encoding:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: Referee, dtype: float64\n",
      "X_train 'HTR' column after mapping:\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: HTR, dtype: object\n",
      "X_test 'HTR' column after mapping:\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: HTR, dtype: object\n",
      "X_train shape after dropping 'Date': (1900, 24)\n",
      "X_test shape after dropping 'Date': (380, 24)\n",
      "X_train after filling missing values:\n",
      "  HomeTeam AwayTeam  FTHG  FTAG FTR  HTHG  HTAG  HTR  Referee    HS  ...  \\\n",
      "0        0       19     1     1   D   1.0   0.0  1.0      0.0   6.0  ...   \n",
      "1        1       18     0     2   A   0.0   0.0  0.0      0.0  11.0  ...   \n",
      "2        2       10     1     1   D   1.0   0.0  1.0      0.0  15.0  ...   \n",
      "3        3       17     1     0   H   1.0   0.0  1.0      0.0   6.0  ...   \n",
      "4        4       13     4     0   H   1.0   0.0  1.0      0.0  12.0  ...   \n",
      "\n",
      "     AF   HC   AC   HY   AY   HR   AR  temperature  wind_speed  precipitation  \n",
      "0  18.0  1.0  8.0  2.0  2.0  1.0  0.0    22.995833   28.020833            0.0  \n",
      "1  11.0  3.0  7.0  1.0  0.0  0.0  0.0    20.550000    6.437500            0.0  \n",
      "2  18.0  5.0  5.0  1.0  2.0  0.0  0.0    18.820833    8.229167            0.0  \n",
      "3  18.0  4.0  3.0  1.0  1.0  0.0  1.0    17.225000    9.391667            0.0  \n",
      "4   9.0  2.0  5.0  1.0  0.0  0.0  0.0    20.612500   13.066667            0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "X_test after filling missing values:\n",
      "  HomeTeam AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  Referee  HS  ...  AF  HC  \\\n",
      "0       12       16     4     0   H     1     0   1      0.0  23  ...  20   5   \n",
      "1       24       30     3     4   A     1     1   0      0.0  21  ...  12   5   \n",
      "2        3        6     3     1   H     1     1   0      0.0  15  ...  13   2   \n",
      "3        0       26     1     2   A     1     0   1      0.0  16  ...  21   4   \n",
      "4        5       18     1     3   A     0     0   0      0.0  16  ...  15   7   \n",
      "\n",
      "   AC  HY  AY  HR  AR  temperature  wind_speed  precipitation  \n",
      "0   1   1   3   0   0    24.787500   17.116667            0.0  \n",
      "1   1   2   2   0   1    18.791667    5.920833            0.0  \n",
      "2   6   1   0   0   0    16.908333    9.216667            1.2  \n",
      "3   2   2   2   0   0    22.904167    8.229167            0.0  \n",
      "4   2   1   0   0   0    19.058333    6.554167            0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Block B3: Prepare Features and Target\n",
    "\n",
    "# Define all columns as features (including weather-related features)\n",
    "features = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'Referee', \n",
    "            'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'temperature', 'wind_speed', 'precipitation']\n",
    "\n",
    "# Prepare features (X) and target (y) for the training data\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['FTR']\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['FTR']\n",
    "\n",
    "# Set pandas option to opt-in to future behavior\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Replace values in y_train and y_test\n",
    "y_train = y_train.replace({'D': 0, 'H': 1, 'A': 2}).infer_objects(copy=False)\n",
    "y_test = y_test.replace({'D': 0, 'H': 1, 'A': 2}).infer_objects(copy=False)\n",
    "\n",
    "# Print the first few rows of y_train and y_test\n",
    "print(\"y_train after replace:\")\n",
    "print(y_train.head())\n",
    "print(\"y_test after replace:\")\n",
    "print(y_test.head())\n",
    "\n",
    "# Map team names in X_train and X_test\n",
    "X_train.loc[:, 'HomeTeam'] = X_train['HomeTeam'].map(team_mapping)\n",
    "X_train.loc[:, 'AwayTeam'] = X_train['AwayTeam'].map(team_mapping)\n",
    "X_test.loc[:, 'HomeTeam'] = X_test['HomeTeam'].map(team_mapping)\n",
    "X_test.loc[:, 'AwayTeam'] = X_test['AwayTeam'].map(team_mapping)\n",
    "\n",
    "# Print transformed X_train and X_test (first few rows)\n",
    "print(\"X_train after team mapping:\")\n",
    "print(X_train.head())\n",
    "print(\"X_test after team mapping:\")\n",
    "print(X_test.head())\n",
    "\n",
    "# Encode referees\n",
    "X_train.loc[:, 'Referee'] = referee_encoder.fit_transform(X_train['Referee'])\n",
    "X_test.loc[:, 'Referee'] = referee_encoder.transform(X_test['Referee'])\n",
    "\n",
    "# Print transformed Referee column\n",
    "print(\"X_train 'Referee' column after encoding:\")\n",
    "print(X_train['Referee'].head())\n",
    "print(\"X_test 'Referee' column after encoding:\")\n",
    "print(X_test['Referee'].head())\n",
    "\n",
    "# Map HTR values\n",
    "X_train.loc[:, 'HTR'] = X_train['HTR'].map({'D': 0, 'H': 1, 'A': 2})\n",
    "X_test.loc[:, 'HTR'] = X_test['HTR'].map({'D': 0, 'H': 1, 'A': 2})\n",
    "\n",
    "# Print transformed 'HTR' column\n",
    "print(\"X_train 'HTR' column after mapping:\")\n",
    "print(X_train['HTR'].head())\n",
    "print(\"X_test 'HTR' column after mapping:\")\n",
    "print(X_test['HTR'].head())\n",
    "\n",
    "# Drop 'Date' column\n",
    "X_train = X_train.drop('Date', axis=1)\n",
    "X_test = X_test.drop('Date', axis=1)\n",
    "\n",
    "# Print shapes after dropping 'Date'\n",
    "print(\"X_train shape after dropping 'Date':\", X_train.shape)\n",
    "print(\"X_test shape after dropping 'Date':\", X_test.shape)\n",
    "\n",
    "# Fill missing numeric values with column means\n",
    "X_train.loc[:, numeric_columns] = X_train[numeric_columns].fillna(X_train[numeric_columns].mean()).infer_objects(copy=False)\n",
    "X_test.loc[:, numeric_columns] = X_test[numeric_columns].fillna(X_test[numeric_columns].mean()).infer_objects(copy=False)\n",
    "\n",
    "# Print first few rows after filling missing values\n",
    "print(\"X_train after filling missing values:\")\n",
    "print(X_train.head())\n",
    "print(\"X_test after filling missing values:\")\n",
    "print(X_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOCK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Train on the encoded target\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Predict the outcomes for both models on the test data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1222\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1222\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/skole/PUC_2/Empirisk/Empirical-Research/myenv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'D'"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(),\n",
    "    'LightGBM': lgb.LGBMClassifier(),\n",
    "    'CatBoost': cb.CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "# Train the models and evaluate\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train_encoded)  # Train on the encoded target\n",
    "    \n",
    "    # Predict the outcomes for both models on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    print(f\"{model_name} accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
